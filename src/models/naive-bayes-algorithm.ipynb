{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "train_path = os.path.join(current_dir, \"../data/train.csv\")\n",
    "test_path = os.path.join(current_dir, \"../data/test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df=None, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['label', 'id', 'FILENAME', 'URL', 'Domain'], axis=1)\n",
    "    y = train_df['label']\n",
    "\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        X[col] = np.log1p(X[col])\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    smote = SMOTE(random_state=random_state, k_neighbors=1)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    if test_df is not None:\n",
    "        X_test_final = test_df.drop(['id', 'FILENAME', 'URL', 'Domain'], axis=1)\n",
    "        for col in numeric_columns:\n",
    "            X_test_final[col] = np.log1p(X_test_final[col])\n",
    "            X_test_final[col] = X_test_final[col].fillna(X_test_final[col].median())\n",
    "        for col in categorical_columns:\n",
    "            X_test_final[col] = X_test_final[col].fillna(X_test_final[col].mode()[0])\n",
    "            X_test_final[col] = X_test_final[col].map(lambda val: label_encoders[col].transform([val])[0]\n",
    "                                                      if val in label_encoders[col].classes_\n",
    "                                                      else -1)\n",
    "        X_test_final[numeric_columns] = scaler.transform(X_test_final[numeric_columns])\n",
    "    else:\n",
    "        X_test_final = None\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, X_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    # NaiveBayes class inisialization\n",
    "    def __init__(self, smoothing=1e-3, prior_adjustment=None):\n",
    "        self.smoothing = smoothing\n",
    "        self.classes_ = None\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "        self.class_counts = {}\n",
    "        self.prior_adjustment = prior_adjustment\n",
    "\n",
    "    # Trains the Naive Bayes model by calculating prior probabilities for each class \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for cls in self.classes_:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "            if self.prior_adjustment and cls in self.prior_adjustment:\n",
    "                self.class_probabilities[cls] *= self.prior_adjustment[cls]\n",
    "\n",
    "            self.class_counts[cls] = np.sum(y == cls)\n",
    "\n",
    "        # Calculate the prior probability for each class\n",
    "        self.feature_probabilities = {cls: [] for cls in self.classes_}\n",
    "        for cls in self.classes_:\n",
    "            X_cls = X[y == cls]\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_vals = X_cls[:, feature_idx]\n",
    "                unique_vals, counts = np.unique(feature_vals, return_counts=True)\n",
    "                feature_prob = {\n",
    "                    val: (count + self.smoothing) / (self.class_counts[cls] + self.smoothing * len(unique_vals))\n",
    "                    for val, count in zip(unique_vals, counts)\n",
    "                }\n",
    "                self.feature_probabilities[cls].append(feature_prob)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # This method calculates the probability of each class for each sample in X\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        probabilities = []\n",
    "        for sample in X:\n",
    "            posteriors = []\n",
    "            for cls in self.classes_:\n",
    "                score = np.log(self.class_probabilities[cls] + self.smoothing)\n",
    "                for feature_idx, feature_val in enumerate(sample):\n",
    "                    feature_prob = self.feature_probabilities[cls][feature_idx].get(feature_val, self.smoothing)\n",
    "                    score += np.log(feature_prob + self.smoothing)\n",
    "                posteriors.append(np.exp(score))\n",
    "            probabilities.append(posteriors / np.sum(posteriors))\n",
    "        return np.array(probabilities)\n",
    "    \n",
    "    # This method determines the predicted class for each sample in the input data\n",
    "    def predict(self, X, threshold=0.005):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            if prob[0] > prob[1] * 0.8: \n",
    "                predictions[i] = 0\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # Saves a trained model to a file.\n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        print(f\"Model saved in {filename}.\")\n",
    "\n",
    "    # Loads a previously saved model from a file for reuse.\n",
    "    @staticmethod\n",
    "    def load_model(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model loaded from {filename}.\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in naive_bayes_model.pkl.\n",
      "Cross-Validation Accuracy (Mean): 94.18%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.08%\n",
      "\n",
      "Naive Bayes kustom classification accuracy: 98.31%\n",
      "\n",
      "Detailed Classification Report (Custom Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87      3166\n",
      "           1       0.98      1.00      0.99     38956\n",
      "\n",
      "    accuracy                           0.98     42122\n",
      "   macro avg       0.99      0.89      0.93     42122\n",
      "weighted avg       0.98      0.98      0.98     42122\n",
      "\n",
      "Predictions saved to 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_test_final = preprocess_data(train_df, test_df)\n",
    "\n",
    "# Train and evaluate model\n",
    "nb = NaiveBayes(prior_adjustment={0: 50.0, 1: 1.0})\n",
    "nb.fit(X_train, y_train)\n",
    "nb.save_model('naive_bayes_model.pkl')\n",
    "\n",
    "# Perform cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = []\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_np):\n",
    "    X_cv_train, X_cv_val = X_train_np[train_idx], X_train_np[val_idx]\n",
    "    y_cv_train, y_cv_val = y_train_np[train_idx], y_train_np[val_idx]\n",
    "\n",
    "    nb_cv = NaiveBayes(prior_adjustment={0: 50.0, 1: 1.0})\n",
    "    nb_cv.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = nb_cv.predict(X_cv_val)\n",
    "    cross_val_scores.append(accuracy_score(y_cv_val, y_cv_pred))\n",
    "\n",
    "print(f\"Cross-Validation Accuracy (Mean): {np.mean(cross_val_scores) * 100:.2f}%\")\n",
    "print(f\"Cross-Validation Accuracy (Standard Deviation): {np.std(cross_val_scores) * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = nb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Detailed Classification Report (Custom Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions = nb.predict(X_test_final)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"label\": predictions\n",
    "})\n",
    "submission_file_path = 'submission.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{submission_file_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
