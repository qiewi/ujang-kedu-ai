{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "train_path = os.path.join(current_dir, \"../data/train.csv\")\n",
    "test_path = os.path.join(current_dir, \"../data/test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df=None, test_size=0.3, random_state=42):\n",
    "    X = train_df.drop(['label', 'id', 'FILENAME', 'URL', 'Domain'], axis=1)\n",
    "    y = train_df['label']\n",
    "\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "    categorical_columns = X.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        X[col] = np.log1p(X[col])\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    smote = SMOTE(random_state=random_state, k_neighbors=1)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    if test_df is not None:\n",
    "        X_test_final = test_df.drop(['id', 'FILENAME', 'URL', 'Domain'], axis=1)\n",
    "        for col in numeric_columns:\n",
    "            X_test_final[col] = np.log1p(X_test_final[col])\n",
    "            X_test_final[col] = X_test_final[col].fillna(X_test_final[col].median())\n",
    "        for col in categorical_columns:\n",
    "            X_test_final[col] = X_test_final[col].fillna(X_test_final[col].mode()[0])\n",
    "            X_test_final[col] = X_test_final[col].map(lambda val: label_encoders[col].transform([val])[0]\n",
    "                                                      if val in label_encoders[col].classes_\n",
    "                                                      else -1)\n",
    "        X_test_final[numeric_columns] = scaler.transform(X_test_final[numeric_columns])\n",
    "    else:\n",
    "        X_test_final = None\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, X_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    # NaiveBayes class inisialization\n",
    "    def __init__(self, smoothing=1e-3, prior_adjustment=None):\n",
    "        self.smoothing = smoothing\n",
    "        self.classes_ = None\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "        self.class_counts = {}\n",
    "        self.prior_adjustment = prior_adjustment\n",
    "\n",
    "    # Trains the Naive Bayes model by calculating prior probabilities for each class \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for cls in self.classes_:\n",
    "            self.class_probabilities[cls] = np.sum(y == cls) / n_samples\n",
    "            if self.prior_adjustment and cls in self.prior_adjustment:\n",
    "                self.class_probabilities[cls] *= self.prior_adjustment[cls]\n",
    "\n",
    "            self.class_counts[cls] = np.sum(y == cls)\n",
    "\n",
    "        # Calculate the prior probability for each class\n",
    "        self.feature_probabilities = {cls: [] for cls in self.classes_}\n",
    "        for cls in self.classes_:\n",
    "            X_cls = X[y == cls]\n",
    "            for feature_idx in range(n_features):\n",
    "                feature_vals = X_cls[:, feature_idx]\n",
    "                unique_vals, counts = np.unique(feature_vals, return_counts=True)\n",
    "                feature_prob = {\n",
    "                    val: (count + self.smoothing) / (self.class_counts[cls] + self.smoothing * len(unique_vals))\n",
    "                    for val, count in zip(unique_vals, counts)\n",
    "                }\n",
    "                self.feature_probabilities[cls].append(feature_prob)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # This method calculates the probability of each class for each sample in X\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        probabilities = []\n",
    "        for sample in X:\n",
    "            posteriors = []\n",
    "            for cls in self.classes_:\n",
    "                score = np.log(self.class_probabilities[cls] + self.smoothing)\n",
    "                for feature_idx, feature_val in enumerate(sample):\n",
    "                    feature_prob = self.feature_probabilities[cls][feature_idx].get(feature_val, self.smoothing)\n",
    "                    score += np.log(feature_prob + self.smoothing)\n",
    "                posteriors.append(np.exp(score))\n",
    "            probabilities.append(posteriors / np.sum(posteriors))\n",
    "        return np.array(probabilities)\n",
    "    \n",
    "    # This method determines the predicted class for each sample in the input data\n",
    "    def predict(self, X, threshold=0.005):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            if prob[0] > prob[1] * 0.8: \n",
    "                predictions[i] = 0\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # Saves a trained model to a file.\n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        print(f\"Model saved in {filename}.\")\n",
    "\n",
    "    # Loads a previously saved model from a file for reuse.\n",
    "    @staticmethod\n",
    "    def load_model(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model loaded from {filename}.\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test, X_test_final \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train and evaluate model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nb \u001b[38;5;241m=\u001b[39m NaiveBayes(prior_adjustment\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m50.0\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1.0\u001b[39m})\n",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(train_df, test_df, test_size, random_state)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m     39\u001b[0m         X_test_final[col] \u001b[38;5;241m=\u001b[39m X_test_final[col]\u001b[38;5;241m.\u001b[39mfillna(X_test_final[col]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 40\u001b[0m         X_test_final[col] \u001b[38;5;241m=\u001b[39m \u001b[43mX_test_final\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     X_test_final[numeric_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test_final[numeric_columns])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[0;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4627\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4703\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m, in \u001b[0;36mpreprocess_data.<locals>.<lambda>\u001b[1;34m(val)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m     39\u001b[0m         X_test_final[col] \u001b[38;5;241m=\u001b[39m X_test_final[col]\u001b[38;5;241m.\u001b[39mfillna(X_test_final[col]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 40\u001b[0m         X_test_final[col] \u001b[38;5;241m=\u001b[39m X_test_final[col]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m val: \u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     41\u001b[0m                                                   \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m label_encoders[col]\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m     42\u001b[0m                                                   \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m     X_test_final[numeric_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test_final[numeric_columns])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([])\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_encode.py:235\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(values\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_encode.py:173\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map values based on its position in uniques.\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(values, uniques)\n\u001b[1;32m--> 173\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43m_nandict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mval\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device\u001b[38;5;241m=\u001b[39mdevice(values))\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_encode.py:160\u001b[0m, in \u001b[0;36m_nandict.__init__\u001b[1;34m(self, mapping)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(mapping)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_scalar_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rizqi Andhika\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_missing.py:42\u001b[0m, in \u001b[0;36mis_scalar_nan\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_scalar_nan\u001b[39m(x):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Test if x is NaN.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    This function is meant to overcome the issue that np.isnan does not allow\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, numbers\u001b[38;5;241m.\u001b[39mIntegral)\n\u001b[1;32m---> 42\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m math\u001b[38;5;241m.\u001b[39misnan(x)\n\u001b[0;32m     44\u001b[0m     )\n",
      "File \u001b[1;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_test_final = preprocess_data(train_df, test_df)\n",
    "\n",
    "# Train and evaluate model\n",
    "nb = NaiveBayes(prior_adjustment={0: 50.0, 1: 1.0})\n",
    "nb.fit(X_train, y_train)\n",
    "nb.save_model('naive_bayes_model.pkl')\n",
    "\n",
    "# Perform cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = []\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_np):\n",
    "    X_cv_train, X_cv_val = X_train_np[train_idx], X_train_np[val_idx]\n",
    "    y_cv_train, y_cv_val = y_train_np[train_idx], y_train_np[val_idx]\n",
    "\n",
    "    nb_cv = NaiveBayes(prior_adjustment={0: 50.0, 1: 1.0})\n",
    "    nb_cv.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = nb_cv.predict(X_cv_val)\n",
    "    cross_val_scores.append(accuracy_score(y_cv_val, y_cv_pred))\n",
    "\n",
    "print(f\"IMPLEMENTATION FROM SCRATCH\")\n",
    "print(f\"Cross-Validation Accuracy (Mean): {np.mean(cross_val_scores) * 100:.2f}%\")\n",
    "print(f\"Cross-Validation Accuracy (Standard Deviation): {np.std(cross_val_scores) * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = nb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nNaive Bayes kustom classification accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Detailed Classification Report (Custom Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions = nb.predict(X_test_final)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"label\": predictions\n",
    "})\n",
    "submission_file_path = 'submission-nb-scratch.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{submission_file_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPLEMENTATION WITH SCIKIT-LEARN\n",
      "Cross-Validation Accuracy (Mean): 92.62%\n",
      "Cross-Validation Accuracy (Standard Deviation): 0.11%\n",
      "\n",
      "Naive Bayes classification accuracy: 98.77%\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      3166\n",
      "           1       0.99      1.00      0.99     38956\n",
      "\n",
      "    accuracy                           0.99     42122\n",
      "   macro avg       0.97      0.94      0.95     42122\n",
      "weighted avg       0.99      0.99      0.99     42122\n",
      "\n",
      "Predictions saved to 'submission-nb-scikit-learn.csv'.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_test_final = preprocess_data(train_df, test_df)\n",
    "\n",
    "# Train and evaluate model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = []\n",
    "\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_np):\n",
    "    X_cv_train, X_cv_val = X_train_np[train_idx], X_train_np[val_idx]\n",
    "    y_cv_train, y_cv_val = y_train_np[train_idx], y_train_np[val_idx]\n",
    "\n",
    "    model.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = model.predict(X_cv_val)\n",
    "    cross_val_scores.append(accuracy_score(y_cv_val, y_cv_pred))\n",
    "\n",
    "print(f\"IMPLEMENTATION WITH SCIKIT-LEARN\")\n",
    "print(f\"Cross-Validation Accuracy (Mean): {np.mean(cross_val_scores) * 100:.2f}%\")\n",
    "print(f\"Cross-Validation Accuracy (Standard Deviation): {np.std(cross_val_scores) * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = model.predict(X_test.values) \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nNaive Bayes classification accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions = model.predict(X_test_final.values)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"label\": predictions\n",
    "})\n",
    "submission_file_path = 'submission-nb-scikit-learn.csv'\n",
    "submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{submission_file_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
